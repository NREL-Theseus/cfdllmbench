{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CFDLLMBench","text":"<p>CFDLLMBench is a comprehensive benchmark suite designed to assess Large Language Models (LLMs) on key competencies relevant to computational fluid dynamics (CFD).</p> <p></p>"},{"location":"#overview","title":"Overview","text":"<p>CFDLLMBench evaluates LLMs across three interconnected tasks:</p> <ul> <li> CFDQuery: Conceptual understanding through multiple-choice CFD questions</li> <li> CFDCodeBench: Instruction-following ability to generate CFD code  </li> <li> FoamBench: End-to-end automation of OpenFOAM simulations from natural language</li> </ul>"},{"location":"#motivation","title":"Motivation","text":"<p>While LLMs excel in general NLP, their ability to reason about scientific systems, generate structured physical code, and interface with domain-specific simulators like OpenFOAM remains underexplored.</p> <p>CFDLLMBench bridges this gap by systematically measuring:</p> <ul> <li>Conceptual grasp of CFD principles (via QA)</li> <li>Structured code generation fidelity</li> <li>Robustness of simulation execution and output</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started with CFDLLMBench in just a few steps:</p> <ol> <li>Installation: Follow our Getting Started Guide</li> <li>Run Benchmarks: Execute the evaluation suite on your LLM</li> <li>Analyze Results: Compare performance across all three tasks</li> </ol>"},{"location":"#key-results","title":"Key Results","text":"<p>Our comprehensive evaluation reveals significant challenges for current LLMs in scientific computing domains, with substantial room for improvement in CFD-specific reasoning and tool use.</p>"},{"location":"#benchmark-components","title":"Benchmark Components","text":""},{"location":"#cfdquery","title":"CFDQuery","text":"<p>90 graduate-level multiple-choice questions covering numerical methods, turbulence modeling, and solver theory.</p>"},{"location":"#cfdcodebench","title":"CFDCodeBench","text":"<p>24 natural language prompts requiring executable CFD code generation with evaluation on correctness and numerical stability.</p>"},{"location":"#foambench","title":"FoamBench","text":"<p>126 OpenFOAM simulation tasks (110 Basic + 16 Advanced) benchmarking end-to-end tool use from case creation to postprocessing.</p> <p>Learn more about our benchmark components \u2192</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Check out our Contributing Guide to get started.</p>"},{"location":"#license","title":"License","text":"<p>This benchmark is open-source and released under the BSD-3-Clause license.</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for CFDLLMBench components.</p>"},{"location":"api/#core-classes","title":"Core Classes","text":""},{"location":"api/#cfdqueryevaluator","title":"CFDQueryEvaluator","text":"<p>Evaluates LLM performance on conceptual CFD questions.</p> <pre><code>class CFDQueryEvaluator:\n    def __init__(self, question_file: str):\n        \"\"\"Initialize evaluator with question dataset.\"\"\"\n\n    def evaluate_model(self, model: LLMInterface) -&gt; Dict[str, float]:\n        \"\"\"Evaluate model and return accuracy metrics.\"\"\"\n\n    def generate_report(self, results: Dict) -&gt; str:\n        \"\"\"Generate detailed evaluation report.\"\"\"\n</code></pre>"},{"location":"api/#methods","title":"Methods","text":"<p><code>evaluate_model(model)</code> - Parameters: <code>model</code> (LLMInterface) - The language model to evaluate - Returns: Dictionary with accuracy scores and detailed metrics - Example: <pre><code>evaluator = CFDQueryEvaluator(\"data/cfdquery.json\")\nresults = evaluator.evaluate_model(my_model)\nprint(f\"Accuracy: {results['accuracy']:.2%}\")\n</code></pre></p>"},{"location":"api/#cfdcodebenchevaluator","title":"CFDCodeBenchEvaluator","text":"<p>Assesses code generation capabilities for CFD problems.</p> <pre><code>class CFDCodeBenchEvaluator:\n    def __init__(self, problems_dir: str):\n        \"\"\"Initialize with CFD problem definitions.\"\"\"\n\n    def evaluate_code(self, generated_code: str, problem_id: str) -&gt; Dict:\n        \"\"\"Evaluate generated code for specific problem.\"\"\"\n\n    def run_full_evaluation(self, model: LLMInterface) -&gt; Dict:\n        \"\"\"Run complete evaluation suite.\"\"\"\n</code></pre>"},{"location":"api/#methods_1","title":"Methods","text":"<p><code>evaluate_code(generated_code, problem_id)</code> - Parameters:    - <code>generated_code</code> (str) - The code generated by LLM   - <code>problem_id</code> (str) - Identifier for the CFD problem - Returns: Evaluation metrics including execution success and accuracy - Example: <pre><code>evaluator = CFDCodeBenchEvaluator(\"data/problems/\")\nresult = evaluator.evaluate_code(llm_code, \"heat_conduction_1d\")\n</code></pre></p>"},{"location":"api/#foambenchevaluator","title":"FoamBenchEvaluator","text":"<p>Manages OpenFOAM simulation automation tasks.</p> <pre><code>class FoamBenchEvaluator:\n    def __init__(self, tasks_dir: str, openfoam_path: str):\n        \"\"\"Initialize with task definitions and OpenFOAM installation.\"\"\"\n\n    def run_task(self, task_id: str, model: LLMInterface) -&gt; TaskResult:\n        \"\"\"Execute single FoamBench task.\"\"\"\n\n    def cleanup_case(self, case_dir: str) -&gt; None:\n        \"\"\"Clean up OpenFOAM case directory.\"\"\"\n</code></pre>"},{"location":"api/#utility-functions","title":"Utility Functions","text":""},{"location":"api/#model-interface","title":"Model Interface","text":"<pre><code>def load_model(model_name: str, **kwargs) -&gt; LLMInterface:\n    \"\"\"Load and configure language model.\"\"\"\n\ndef batch_evaluate(models: List[str], evaluators: List[Evaluator]) -&gt; DataFrame:\n    \"\"\"Run batch evaluation across multiple models.\"\"\"\n</code></pre>"},{"location":"api/#data-processing","title":"Data Processing","text":"<pre><code>def load_cfd_questions(file_path: str) -&gt; List[Question]:\n    \"\"\"Load CFDQuery dataset.\"\"\"\n\ndef parse_openfoam_case(case_dir: str) -&gt; CaseConfig:\n    \"\"\"Parse OpenFOAM case configuration.\"\"\"\n\ndef compute_similarity_metrics(generated: Array, reference: Array) -&gt; Dict:\n    \"\"\"Compute numerical similarity between outputs.\"\"\"\n</code></pre>"},{"location":"api/#configuration","title":"Configuration","text":""},{"location":"api/#model-configuration","title":"Model Configuration","text":"<pre><code># config.yaml\nmodels:\n  openai:\n    api_key: \"${OPENAI_API_KEY}\"\n    model: \"gpt-4\"\n    temperature: 0.1\n    max_tokens: 2048\n\n  anthropic:\n    api_key: \"${ANTHROPIC_API_KEY}\"  \n    model: \"claude-2\"\n    temperature: 0.1\n</code></pre>"},{"location":"api/#evaluation-settings","title":"Evaluation Settings","text":"<pre><code>evaluation:\n  timeout: 300  # seconds\n  max_retries: 3\n  parallel_jobs: 4\n\nopenfoam:\n  version: \"8\"\n  mpi_processes: 4\n  case_timeout: 1800\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":""},{"location":"api/#common-exceptions","title":"Common Exceptions","text":"<pre><code>class CFDBenchError(Exception):\n    \"\"\"Base exception for CFDLLMBench.\"\"\"\n\nclass ModelTimeoutError(CFDBenchError):\n    \"\"\"Raised when model response times out.\"\"\"\n\nclass OpenFOAMError(CFDBenchError):\n    \"\"\"Raised when OpenFOAM execution fails.\"\"\"\n\nclass CodeExecutionError(CFDBenchError):\n    \"\"\"Raised when generated code fails to execute.\"\"\"\n</code></pre>"},{"location":"api/#examples","title":"Examples","text":""},{"location":"api/#complete-evaluation","title":"Complete Evaluation","text":"<pre><code>from cfdllmbench import CFDQueryEvaluator, CFDCodeBenchEvaluator, FoamBenchEvaluator\nfrom cfdllmbench.models import OpenAIModel\n\n# Initialize model\nmodel = OpenAIModel(\"gpt-4\", api_key=\"your-key\")\n\n# Run all evaluations\ncfdquery_eval = CFDQueryEvaluator(\"data/cfdquery.json\")\ncodebench_eval = CFDCodeBenchEvaluator(\"data/problems/\")\nfoambench_eval = FoamBenchEvaluator(\"data/foam_tasks/\", \"/opt/openfoam8\")\n\n# Get results\nquery_results = cfdquery_eval.evaluate_model(model)\ncode_results = codebench_eval.run_full_evaluation(model)\nfoam_results = foambench_eval.run_all_tasks(model)\n\nprint(f\"CFDQuery Accuracy: {query_results['accuracy']:.2%}\")\nprint(f\"CodeBench Success: {code_results['success_rate']:.2%}\")\nprint(f\"FoamBench Success: {foam_results['success_rate']:.2%}\")\n</code></pre>"},{"location":"contributing/","title":"Contributing to CFDLLMBench","text":"<p>We welcome contributions from the community! This guide will help you get started.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Bug Reports: Report issues you encounter</li> <li>Feature Requests: Suggest new evaluation tasks or metrics</li> <li>Code Contributions: Implement improvements or new features</li> <li>Documentation: Improve documentation and examples</li> <li>Datasets: Contribute additional CFD problems or test cases</li> </ul>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork the repository on GitHub, then:\ngit clone https://github.com/YOUR_USERNAME/cfdllmbench.git\ncd cfdllmbench\n</code></pre>"},{"location":"contributing/#2-set-up-development-environment","title":"2. Set Up Development Environment","text":"<pre><code># Create virtual environment\npython -m venv cfd_env\nsource cfd_env/bin/activate  # On Windows: cfd_env\\Scripts\\activate\n\n# Install development dependencies\npip install -r requirements-dev.txt\npip install -e .\n</code></pre>"},{"location":"contributing/#3-run-tests","title":"3. Run Tests","text":"<pre><code># Run the test suite\npytest tests/\n\n# Run with coverage\npytest --cov=cfdllmbench tests/\n</code></pre>"},{"location":"contributing/#development-guidelines","title":"Development Guidelines","text":""},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We follow PEP 8 with some modifications:</p> <pre><code># Use black for formatting\nblack cfdllmbench/\n\n# Use flake8 for linting  \nflake8 cfdllmbench/\n\n# Use mypy for type checking\nmypy cfdllmbench/\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Document all public functions and classes</li> <li>Use Google-style docstrings</li> <li>Include examples in docstrings</li> <li>Update API documentation when adding features</li> </ul> <pre><code>def evaluate_model(self, model: LLMInterface) -&gt; Dict[str, float]:\n    \"\"\"Evaluate language model on CFD questions.\n\n    Args:\n        model: The language model interface to evaluate.\n\n    Returns:\n        Dictionary containing accuracy and detailed metrics.\n\n    Example:\n        &gt;&gt;&gt; evaluator = CFDQueryEvaluator(\"questions.json\")\n        &gt;&gt;&gt; results = evaluator.evaluate_model(my_model)\n        &gt;&gt;&gt; print(f\"Accuracy: {results['accuracy']:.2%}\")\n    \"\"\"\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>Write tests for all new functionality</li> <li>Aim for &gt;90% test coverage</li> <li>Use pytest fixtures for setup</li> <li>Test both success and failure cases</li> </ul> <pre><code>def test_cfdquery_evaluation():\n    \"\"\"Test CFDQuery evaluation with mock model.\"\"\"\n    evaluator = CFDQueryEvaluator(\"test_data/questions.json\")\n    mock_model = MockLLM(responses=[\"A\", \"B\", \"C\", \"D\"])\n\n    results = evaluator.evaluate_model(mock_model)\n\n    assert \"accuracy\" in results\n    assert 0 &lt;= results[\"accuracy\"] &lt;= 1\n</code></pre>"},{"location":"contributing/#adding-new-components","title":"Adding New Components","text":""},{"location":"contributing/#1-new-evaluation-task","title":"1. New Evaluation Task","text":"<p>To add a new evaluation component:</p> <pre><code># 1. Create evaluator class\nclass NewTaskEvaluator:\n    def __init__(self, config_file: str):\n        self.config = load_config(config_file)\n\n    def evaluate_model(self, model: LLMInterface) -&gt; Dict:\n        # Implementation here\n        pass\n\n# 2. Add to main benchmark\nclass CFDLLMBench:\n    def add_evaluator(self, name: str, evaluator: Evaluator):\n        self.evaluators[name] = evaluator\n</code></pre>"},{"location":"contributing/#2-new-model-interface","title":"2. New Model Interface","text":"<p>To support a new LLM provider:</p> <pre><code>class NewModelInterface(LLMInterface):\n    def __init__(self, model_name: str, **kwargs):\n        self.model_name = model_name\n        # Initialize model connection\n\n    def generate(self, prompt: str) -&gt; str:\n        # Implement model inference\n        pass\n\n    def batch_generate(self, prompts: List[str]) -&gt; List[str]:\n        # Implement batch inference\n        pass\n</code></pre>"},{"location":"contributing/#submitting-changes","title":"Submitting Changes","text":""},{"location":"contributing/#1-create-feature-branch","title":"1. Create Feature Branch","text":"<pre><code>git checkout -b feature/new-evaluation-task\n</code></pre>"},{"location":"contributing/#2-make-changes","title":"2. Make Changes","text":"<ul> <li>Follow coding guidelines</li> <li>Add tests for new functionality</li> <li>Update documentation</li> <li>Ensure all tests pass</li> </ul>"},{"location":"contributing/#3-commit-changes","title":"3. Commit Changes","text":"<pre><code>git add .\ngit commit -m \"Add new CFD evaluation task\n\n- Implement heat transfer problem set\n- Add corresponding test cases  \n- Update documentation\"\n</code></pre>"},{"location":"contributing/#4-submit-pull-request","title":"4. Submit Pull Request","text":"<ol> <li>Push branch to your fork</li> <li>Create pull request on GitHub</li> <li>Describe changes and motivation</li> <li>Link to relevant issues</li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":""},{"location":"contributing/#checklist","title":"Checklist","text":"<ul> <li> Code follows style guidelines</li> <li> Tests added for new functionality</li> <li> All tests pass</li> <li> Documentation updated</li> <li> Changelog entry added</li> <li> No merge conflicts</li> </ul>"},{"location":"contributing/#review-process","title":"Review Process","text":"<ol> <li>Automated checks: CI runs tests and style checks</li> <li>Code review: Maintainers review changes</li> <li>Discussion: Address feedback and questions</li> <li>Approval: Changes approved by maintainer</li> <li>Merge: Changes merged to main branch</li> </ol>"},{"location":"contributing/#community","title":"Community","text":""},{"location":"contributing/#communication","title":"Communication","text":"<ul> <li>GitHub Issues: Bug reports and feature requests</li> <li>Discussions: General questions and ideas</li> <li>Email: Direct contact for sensitive issues</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>We are committed to providing a welcoming and inclusive experience for everyone. Please read our Code of Conduct.</p>"},{"location":"contributing/#recognition","title":"Recognition","text":"<p>Contributors are recognized in:</p> <ul> <li>Release notes</li> <li>Contributors file</li> <li>Project documentation</li> <li>Conference papers (for significant contributions)</li> </ul> <p>Thank you for contributing to CFDLLMBench!</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you set up and run CFDLLMBench to evaluate Large Language Models on CFD tasks.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>OpenFOAM (for FoamBench evaluation)</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/NREL-Theseus/cfdllmbench.git\ncd cfdllmbench\n</code></pre>"},{"location":"getting-started/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#3-set-up-openfoam-optional","title":"3. Set Up OpenFOAM (Optional)","text":"<p>For FoamBench evaluation, install OpenFOAM:</p> <pre><code># Ubuntu/Debian\nsudo apt-get install openfoam\n\n# Or follow official OpenFOAM installation guide\n</code></pre>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":""},{"location":"getting-started/#running-cfdquery","title":"Running CFDQuery","text":"<p>Evaluate conceptual understanding with multiple-choice questions:</p> <pre><code>python run_cfdquery.py --model gpt-3.5-turbo --output results/\n</code></pre>"},{"location":"getting-started/#running-cfdcodebench","title":"Running CFDCodeBench","text":"<p>Test code generation capabilities:</p> <pre><code>python run_cfdcodebench.py --model gpt-3.5-turbo --output results/\n</code></pre>"},{"location":"getting-started/#running-foambench","title":"Running FoamBench","text":"<p>Assess end-to-end OpenFOAM automation:</p> <pre><code>python run_foambench.py --model gpt-3.5-turbo --level basic --output results/\n</code></pre>"},{"location":"getting-started/#configuration","title":"Configuration","text":"<p>Configure your LLM API keys and settings in <code>config.yaml</code>:</p> <pre><code>models:\n  openai:\n    api_key: \"your-api-key-here\"\n    model: \"gpt-3.5-turbo\"\n\nevaluation:\n  timeout: 300\n  max_retries: 3\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Benchmark Components</li> <li>View Results and Analysis</li> <li>Check API Reference</li> </ul>"},{"location":"results/","title":"Results and Analysis","text":"<p>This page presents comprehensive evaluation results across all CFDLLMBench components.</p>"},{"location":"results/#overall-performance","title":"Overall Performance","text":""},{"location":"results/#key-findings","title":"Key Findings","text":""},{"location":"results/#1-conceptual-understanding-cfdquery","title":"1. Conceptual Understanding (CFDQuery)","text":"<ul> <li>Best performer: GPT-4 (72% accuracy)</li> <li>Common failure modes: Complex turbulence questions, numerical stability concepts</li> <li>Observation: Strong correlation with general reasoning abilities</li> </ul>"},{"location":"results/#2-code-generation-cfdcodebench","title":"2. Code Generation (CFDCodeBench)","text":"<ul> <li>Best performer: Code-specialized models</li> <li>Success rate: 45-65% for execution, 30-50% for correctness</li> <li>Challenge areas: Boundary condition implementation, solver selection</li> </ul>"},{"location":"results/#3-tool-integration-foambench","title":"3. Tool Integration (FoamBench)","text":"<ul> <li>Basic tasks: 40-60% success rate</li> <li>Advanced tasks: 10-25% success rate  </li> <li>Bottlenecks: Case setup syntax, solver configuration</li> </ul>"},{"location":"results/#comparative-analysis","title":"Comparative Analysis","text":""},{"location":"results/#by-model-family","title":"By Model Family","text":"Model CFDQuery CFDCodeBench FoamBench GPT-4 72% 58% 42% GPT-3.5 54% 41% 28% Claude-2 68% 52% 35% Code-Llama 35% 62% 31%"},{"location":"results/#performance-trends","title":"Performance Trends","text":"<ol> <li>Scale effects: Larger models generally perform better</li> <li>Specialization matters: Code-focused models excel at implementation</li> <li>Domain knowledge: Scientific training improves conceptual understanding</li> <li>Tool use gap: Significant room for improvement in automation tasks</li> </ol>"},{"location":"results/#error-analysis","title":"Error Analysis","text":""},{"location":"results/#common-failure-patterns","title":"Common Failure Patterns","text":""},{"location":"results/#cfdquery","title":"CFDQuery","text":"<ul> <li>Misconceptions about turbulence modeling</li> <li>Confusion between numerical methods</li> <li>Boundary condition misunderstanding</li> </ul>"},{"location":"results/#cfdcodebench","title":"CFDCodeBench","text":"<ul> <li>Incorrect discretization schemes</li> <li>Missing convergence checks</li> <li>Improper boundary implementation</li> </ul>"},{"location":"results/#foambench","title":"FoamBench","text":"<ul> <li>Syntax errors in OpenFOAM files</li> <li>Inappropriate solver selection</li> <li>Missing required files</li> </ul>"},{"location":"results/#improvement-opportunities","title":"Improvement Opportunities","text":"<ol> <li>Better scientific training data</li> <li>Tool-specific fine-tuning </li> <li>Multi-step reasoning enhancement</li> <li>Error recovery mechanisms</li> </ol>"},{"location":"results/#reproducibility","title":"Reproducibility","text":"<p>All results can be reproduced using:</p> <pre><code># Full evaluation suite\npython run_full_benchmark.py --models all --output results/\n\n# Generate plots\npython analyze_results.py --input results/ --output figures/\n</code></pre>"},{"location":"results/#citation","title":"Citation","text":"<p>If you use these results in your research, please cite:</p> <pre><code>@article{cfdllmbench2024,\n  title={CFDLLMBench: A Comprehensive Benchmark for Large Language Models in Computational Fluid Dynamics},\n  author={Your Authors},\n  journal={Journal Name},\n  year={2024}\n}\n</code></pre>"},{"location":"components/cfdcodebench/","title":"CFDCodeBench: Code Generation","text":"<p>CFDCodeBench assesses LLMs' ability to generate executable CFD code from natural language descriptions.</p>"},{"location":"components/cfdcodebench/#overview","title":"Overview","text":"<ul> <li>24 diverse CFD problems with varying complexity</li> <li>Multiple implementation approaches (FDM, FVM, analytical)</li> <li>Execution-based evaluation with numerical verification</li> </ul>"},{"location":"components/cfdcodebench/#problem-categories","title":"Problem Categories","text":""},{"location":"components/cfdcodebench/#basic-problems","title":"Basic Problems","text":"<ul> <li>1D heat conduction</li> <li>Simple flow calculations</li> <li>Analytical solutions</li> </ul>"},{"location":"components/cfdcodebench/#intermediate-problems","title":"Intermediate Problems","text":"<ul> <li>2D heat transfer</li> <li>Navier-Stokes equations</li> <li>Boundary layer analysis</li> </ul>"},{"location":"components/cfdcodebench/#advanced-problems","title":"Advanced Problems","text":"<ul> <li>Turbulent flows</li> <li>Multi-physics coupling</li> <li>Complex geometries</li> </ul>"},{"location":"components/cfdcodebench/#example-problem","title":"Example Problem","text":"<p>Problem: \"Write Python code to solve 1D steady-state heat conduction with constant thermal conductivity. Use finite difference method with Dirichlet boundary conditions T(0)=100\u00b0C and T(L)=0\u00b0C.\"</p> <p>Expected Output: Working Python code that: - Implements finite difference discretization - Applies boundary conditions correctly - Solves the linear system - Returns temperature distribution</p>"},{"location":"components/cfdcodebench/#evaluation-metrics","title":"Evaluation Metrics","text":""},{"location":"components/cfdcodebench/#1-execution-success","title":"1. Execution Success","text":"<pre><code>def check_execution(code):\n    try:\n        exec(code)\n        return True\n    except:\n        return False\n</code></pre>"},{"location":"components/cfdcodebench/#2-numerical-accuracy","title":"2. Numerical Accuracy","text":"<pre><code>def compute_similarity(generated_output, reference_output):\n    return 1 - np.mean(np.abs(generated_output - reference_output))\n</code></pre>"},{"location":"components/cfdcodebench/#3-code-quality","title":"3. Code Quality","text":"<ul> <li>Proper error handling</li> <li>Appropriate algorithms</li> <li>Clear structure</li> </ul>"},{"location":"components/cfdcodebench/#running-cfdcodebench","title":"Running CFDCodeBench","text":"<pre><code>python run_cfdcodebench.py --model your_model --problems all --output results/\n</code></pre>"},{"location":"components/cfdquery/","title":"CFDQuery: Conceptual Understanding","text":"<p>CFDQuery evaluates LLMs' conceptual understanding of computational fluid dynamics through carefully curated multiple-choice questions.</p>"},{"location":"components/cfdquery/#overview","title":"Overview","text":"<ul> <li>90 graduate-level questions from CFD lecture materials</li> <li>Four-choice format with single correct answer</li> <li>Comprehensive coverage of key CFD concepts</li> </ul>"},{"location":"components/cfdquery/#topics-covered","title":"Topics Covered","text":""},{"location":"components/cfdquery/#numerical-methods","title":"Numerical Methods","text":"<ul> <li>Finite difference methods</li> <li>Finite volume methods  </li> <li>Finite element methods</li> <li>Discretization schemes</li> <li>Stability and convergence</li> </ul>"},{"location":"components/cfdquery/#turbulence-modeling","title":"Turbulence Modeling","text":"<ul> <li>Reynolds-averaged equations</li> <li>Large eddy simulation</li> <li>Direct numerical simulation</li> <li>Turbulence models (k-\u03b5, k-\u03c9, RSM)</li> </ul>"},{"location":"components/cfdquery/#solver-theory","title":"Solver Theory","text":"<ul> <li>Pressure-velocity coupling</li> <li>Solution algorithms</li> <li>Boundary conditions</li> <li>Grid generation</li> </ul>"},{"location":"components/cfdquery/#example-question","title":"Example Question","text":"<p>What is the primary advantage of the finite volume method over finite difference methods?</p> <p>A) Higher-order accuracy B) Conservation properties C) Computational efficiency D) Easier implementation</p> <p>Correct Answer: B - Conservation properties</p>"},{"location":"components/cfdquery/#evaluation","title":"Evaluation","text":"<p>Models are scored based on accuracy: the percentage of questions answered correctly.</p> <pre><code>def evaluate_cfdquery(responses, ground_truth):\n    correct = sum(1 for r, gt in zip(responses, ground_truth) if r == gt)\n    return correct / len(ground_truth)\n</code></pre>"},{"location":"components/cfdquery/#running-cfdquery","title":"Running CFDQuery","text":"<pre><code>python run_cfdquery.py --model your_model --output results/cfdquery/\n</code></pre>"},{"location":"components/foambench/","title":"FoamBench: OpenFOAM Automation","text":"<p>FoamBench evaluates end-to-end automation capabilities for OpenFOAM simulations from natural language instructions.</p>"},{"location":"components/foambench/#overview","title":"Overview","text":"<ul> <li>126 total tasks: 110 Basic + 16 Advanced</li> <li>Complete workflow: Case setup \u2192 Execution \u2192 Post-processing</li> <li>Real OpenFOAM integration with actual simulation runs</li> </ul>"},{"location":"components/foambench/#task-categories","title":"Task Categories","text":""},{"location":"components/foambench/#basic-tasks-110","title":"Basic Tasks (110)","text":"<ul> <li>Standard solvers (simpleFoam, pimpleFoam)</li> <li>Common geometries (channel, cylinder, cavity)</li> <li>Standard boundary conditions</li> <li>Basic post-processing</li> </ul>"},{"location":"components/foambench/#advanced-tasks-16","title":"Advanced Tasks (16)","text":"<ul> <li>Custom boundary conditions</li> <li>Complex geometries</li> <li>Multi-phase flows</li> <li>Advanced post-processing</li> <li>Parameter studies</li> </ul>"},{"location":"components/foambench/#workflow-steps","title":"Workflow Steps","text":""},{"location":"components/foambench/#1-case-creation","title":"1. Case Creation","text":"<pre><code># Example: Create channel flow case\nblockMesh\n# Generate computational mesh\n</code></pre>"},{"location":"components/foambench/#2-boundary-conditions","title":"2. Boundary Conditions","text":"<pre><code>// Example boundary condition setup\ninlet\n{\n    type            fixedValue;\n    value           uniform (1 0 0);\n}\n</code></pre>"},{"location":"components/foambench/#3-solver-execution","title":"3. Solver Execution","text":"<pre><code># Run appropriate solver\nsimpleFoam\n</code></pre>"},{"location":"components/foambench/#4-post-processing","title":"4. Post-processing","text":"<pre><code># Extract results\npostProcess -func wallShearStress\n</code></pre>"},{"location":"components/foambench/#example-task","title":"Example Task","text":"<p>Instruction: \"Set up a 2D channel flow simulation with Re=1000. Use a 100x20 mesh, inlet velocity 1 m/s, and extract pressure drop across the channel.\"</p> <p>Expected Actions: 1. Create blockMeshDict for 100x20 mesh 2. Set inlet velocity boundary condition 3. Configure simpleFoam solver 4. Run simulation 5. Calculate pressure drop</p>"},{"location":"components/foambench/#evaluation","title":"Evaluation","text":""},{"location":"components/foambench/#success-criteria","title":"Success Criteria","text":"<ul> <li>Case setup completes without errors</li> <li>Simulation converges successfully  </li> <li>Required outputs are generated</li> <li>Results are physically reasonable</li> </ul>"},{"location":"components/foambench/#scoring","title":"Scoring","text":"<pre><code>def evaluate_foambench_task(task_result):\n    score = 0\n    if task_result.setup_success:\n        score += 0.3\n    if task_result.execution_success:\n        score += 0.4  \n    if task_result.postprocess_success:\n        score += 0.3\n    return score\n</code></pre>"},{"location":"components/foambench/#running-foambench","title":"Running FoamBench","text":"<pre><code># Basic tasks\npython run_foambench.py --level basic --model your_model\n\n# Advanced tasks  \npython run_foambench.py --level advanced --model your_model\n\n# Specific task\npython run_foambench.py --task channel_flow --model your_model\n</code></pre>"},{"location":"components/foambench/#prerequisites","title":"Prerequisites","text":"<ul> <li>OpenFOAM 8+ installed and configured</li> <li>Sufficient computational resources</li> <li>Write permissions for case directories</li> </ul>"},{"location":"components/overview/","title":"Benchmark Components Overview","text":"<p>CFDLLMBench consists of three complementary evaluation tasks designed to comprehensively assess LLM capabilities in computational fluid dynamics.</p>"},{"location":"components/overview/#design-philosophy","title":"Design Philosophy","text":"<p>Our benchmark follows a hierarchical evaluation approach:</p> <ol> <li>Conceptual Understanding (CFDQuery) - Foundation knowledge</li> <li>Code Generation (CFDCodeBench) - Applied implementation  </li> <li>Tool Integration (FoamBench) - End-to-end automation</li> </ol>"},{"location":"components/overview/#component-breakdown","title":"Component Breakdown","text":"Component Type Tasks Evaluation Metric CFDQuery Multiple Choice 90 questions Accuracy CFDCodeBench Code Generation 24 problems Execution + Similarity FoamBench Tool Use 126 simulations Success Rate"},{"location":"components/overview/#evaluation-pipeline","title":"Evaluation Pipeline","text":"<pre><code>graph LR\n    A[Input Query] --&gt; B[LLM Response]\n    B --&gt; C{Component Type}\n    C --&gt;|CFDQuery| D[Answer Matching]\n    C --&gt;|CFDCodeBench| E[Code Execution]\n    C --&gt;|FoamBench| F[Simulation Success]\n    D --&gt; G[Score Calculation]\n    E --&gt; G\n    F --&gt; G</code></pre>"},{"location":"components/overview/#learn-more","title":"Learn More","text":"<ul> <li>CFDQuery Details</li> <li>CFDCodeBench Details </li> <li>FoamBench Details</li> </ul>"}]}